#!/usr/bin/env bash
#
# Generates OLM bundle using existing CRDs
#
#
set -euo pipefail
set -x

# shellcheck source=/dev/null
source "$(dirname "$(realpath "$0")")/../multi-platform-support.sh"

PACKAGE_NAME=strimzi-kafka-operator
CSV_NAME_PREFIX=strimzi-cluster-operator
CHANNELS=latest
PREVIOUS_BUNDLE_VERSION=$(curl -s https://raw.githubusercontent.com/k8s-operatorhub/community-operators/main/operators/strimzi-kafka-operator/strimzi-kafka-operator.package.yaml | yq e '.channels[0].currentCSV' -)

CSV_TEMPLATE_DIR="$(dirname "$(realpath "$0")")/csv-template"
CSV_TEMPLATE=${CSV_TEMPLATE_DIR}/bases/${CSV_NAME_PREFIX}.clusterserviceversion.yaml

CRD_DIR="$(dirname "$(realpath "$0")")/../../packaging/install/cluster-operator"
BUILD_ENGINE=${BUILD_ENGINE}

for ARGUMENT in "$@"
do
  KEY=$(echo "$ARGUMENT" | cut -f1 -d=)
  VALUE=$(echo "$ARGUMENT" | cut -f2 -d=)

  case "$KEY" in
    DOCKER_REGISTRY)    DOCKER_REGISTRY=${VALUE} ;;
    DOCKER_ORG)              DOCKER_ORG=${VALUE} ;;
    DOCKER_TAG)              DOCKER_TAG=${VALUE} ;;
    BUNDLE_VERSION)      BUNDLE_VERSION=${VALUE} ;;
	ARCH)     			 ARCH=${VALUE} ;;
	BUNDLE_IMAGE)	 BUNDLE_IMAGE=${VALUE} ;;
	BUNDLE_IMAGE_TAG)	 BUNDLE_IMAGE_TAG=${VALUE} ;;
	INDEX_IMAGE)	 INDEX_IMAGE=${VALUE} ;;
	INDEX_IMAGE_TAG)	 INDEX_IMAGE_TAG=${VALUE} ;;
    *)
  esac
done

BUNDLE="$(dirname "$(realpath "$0")")/bundle"
CATALOG_DIR="$(dirname "$(realpath "$0")")/catalog"
MANIFESTS=${BUNDLE}/manifests
DOCKERFILE=${BUNDLE}/bundle.Dockerfile

CSV_FILE="${MANIFESTS}/${CSV_NAME_PREFIX}.v${BUNDLE_VERSION}.clusterserviceversion.yaml"

if [[ -z $BUNDLE_VERSION || -z $DOCKER_REGISTRY || -z $DOCKER_ORG || -z $DOCKER_TAG ]]; then
  echo "One or more arguments have not been supplied
Try running:
  ./generate-olm-bundle.sh BUNDLE_VERSION=<BUNDLE_VERSION> DOCKER_REGISTRY=<DOCKER_REGISTRY> DOCKER_ORG=<DOCKER_ORG> DOCKER_TAG=<DOCKER_TAG> ARCH=<ARCH> BUNDLE_IMAGE=<BUNDLE_IMAGE> BUNDLE_IMAGE_TAG=<BUNDLE_IMAGE_TAG> INDEX_IMAGE=<INDEX_IMAGE> INDEX_IMAGE_TAG=<INDEX_IMAGE_TAG>
e.g.
  ./generate-olm-bundle.sh BUNDLE_VERSION=0.33.0 DOCKER_REGISTRY=quay.io.io DOCKER_ORG=strimzi DOCKER_TAG=0.33.0 ARCH=amd64 BUNDLE_IMAGE=quay.io/strimzi/operator-bundle BUNDLE_IMAGE_TAG=latest INDEX_IMAGE=quay.io/strimzi/operator-iib INDEX_IMAGE_TAG=latest
"
  exit 1
fi

# In order for the operator-sdk to correctly generate a CSV file the CSV_TEMPLATE file
# must have the format ${CSV_TEMPLATE_DIR}/bases/${PACKAGE_NAME}.clusterserviceversion.yaml
if [ ! -f "$CSV_TEMPLATE" ];
then
  echo "ERROR: CSV_TEMPLATE does not follow the format ${CSV_TEMPLATE_DIR}/bases/${CSV_NAME_PREFIX}.clusterserviceversion.yaml"
  exit 1
fi

# In order for the operator-sdk to correctly generate a CSV file the CSV_TEMPLATE file
# metadata.name must of be the format "${PACKAGE_NAME}.v"
CSV_TEMPLATE_METADATA_NAME=$(yq ea '.metadata.name' "${CSV_TEMPLATE}" )
if [[ $CSV_TEMPLATE_METADATA_NAME != ${CSV_NAME_PREFIX}.v* ]];
then
  echo "ERROR: CSV_TEMPLATE metadata.name is not of the format ${CSV_NAME_PREFIX}.v"
  exit 1 
fi

# Generates bundle from existing CRDs
generate_olm_bundle() { 
  rm -rf "${BUNDLE}"
  # To generate a bundle from existing CRDs using the operator-sdk we must:
  #   1.) Specify package name "--package" and bundle version "--version"
  #   2.) Set `--input-dir` to the directory containing CRDs
  #   3.) Place our template CSV file in a directory in the kustomize format: 
  #       "<some-dir>/bases/<package-name>.clusterserviceversion.yaml"
  # *Note* the package name must match the name used in the CSV template
  operator-sdk generate bundle \
	  --input-dir="$CRD_DIR" \
	  --output-dir="$BUNDLE" \
	  --kustomize-dir="$CSV_TEMPLATE_DIR" \
	  --package="$CSV_NAME_PREFIX" \
	  --version="$BUNDLE_VERSION" \
	  --channels="$CHANNELS"

  # We have different package name and CSV name so we need to change this in metadata otherwise OPM will generate it wrongly
  ${SED} -i "s#strimzi-cluster-operator#strimzi-kafka-operator#" ${BUNDLE}/metadata/annotations.yaml

  # Move Dockerfile generated by operator-sdk
  mv ./bundle.Dockerfile "$DOCKERFILE"
  
  # Remove last three lines of Dockerfile with incorrectly generated paths
  $HEAD -n -3 "$DOCKERFILE" | $TEE "$DOCKERFILE" 1> /dev/null

  # Add copy commands with correct paths
  echo "COPY ./manifests/ /manifests/" >> "$DOCKERFILE"
  echo "COPY ./metadata/ /metadata/" >> "$DOCKERFILE"
  
  # Rename config map
  mv "${MANIFESTS}/strimzi-cluster-operator_v1_configmap.yaml" "${MANIFESTS}/strimziclusteroperator.configmap.yaml"

  # Update CSV filename to name traditionally used for OperatorHub
  mv "${MANIFESTS}"/*.clusterserviceversion.yaml "${CSV_FILE}"
  
  # Change the copied CRD names to the names traditionally used for OperatorHub
  for file in "$MANIFESTS"/*; do
    name=$(yq ea '.metadata.name' "${file}")
    kind=$(yq ea '.kind' "${file}")
    if [ "$kind" = "CustomResourceDefinition" ] || [ "$kind" = "ConfigMap" ] ||  [ "$kind" = "ClusterRole" ]; then
      if [ "$kind" = "CustomResourceDefinition" ]; then
        kind="crd"
      else
        name=$(echo "$name" | $SED 's/-//g')
        kind=$(echo "$kind" | tr '[:upper:]' '[:lower:]')
      fi
      dest="${MANIFESTS}/${name}.${kind}.yaml"
      echo "Update CRD filename $(basename "$file") -> $(basename "$dest")"
      mv "$file" "$dest"
    fi
  done
  
  # Copy missing files not added by operator-sdk
  $CP "${CRD_DIR}/030-ClusterRole-strimzi-kafka-broker.yaml" "${MANIFESTS}/strimzikafkabroker.clusterrole.yaml"
  $CP "${CRD_DIR}/031-ClusterRole-strimzi-entity-operator.yaml" "${MANIFESTS}/strimzientityoperator.clusterrole.yaml"
  $CP "${CRD_DIR}/033-ClusterRole-strimzi-kafka-client.yaml" "${MANIFESTS}/strimzikafkaclient.clusterrole.yaml" 
 
  # Update annotations
  yq ea -i 'select(fi==0).metadata.annotations = select(fi==1).metadata.annotations | select(fi==0)' "${CSV_FILE}" "${CSV_TEMPLATE}"
  
  # Update creation timestamp
  yq ea -i ".metadata.annotations.createdAt = \"$(date +'%Y-%m-%d %H:%M:%S')\"" "${CSV_FILE}"

  # Remove unused fields
  yq ea -i "del(.spec.apiservicedefinitions)" "${CSV_FILE}"

  yq ea -i '.spec.install.spec = null' "${CSV_FILE}"
  yq ea -i '.spec.install.spec = {"permissions" : null, "clusterPermissions": null, "deployments": null}' "${CSV_FILE}"
  
  # Update permissions section with namespaced RBAC rules with Cluster Operator roles + Entity Operator roles
  yq ea -i '.spec.install.spec.permissions = [{"rules" : "", "serviceAccountName" : "strimzi-cluster-operator"}]' "${CSV_FILE}"
  yq ea -i 'select(fi==0).spec.install.spec.permissions[0].rules = select(fi==1).rules + select(fi==2).rules + select(fi==3).rules + select(fi==4).rules | select(fi==0)' \
   "${CSV_FILE}" \
   "${CRD_DIR}/020-ClusterRole-strimzi-cluster-operator-role.yaml" \
   "${CRD_DIR}/022-ClusterRole-strimzi-cluster-operator-role.yaml" \
   "${CRD_DIR}/023-ClusterRole-strimzi-cluster-operator-role.yaml" \
   "${CRD_DIR}/031-ClusterRole-strimzi-entity-operator.yaml"
  
  # Update clusterPermissions section with global RBAC rules (operator-sdk incorrectly copys other ClusterRoles here)
  yq ea -i '.spec.install.spec.clusterPermissions = [{"rules" : "", "serviceAccountName" : "strimzi-cluster-operator"}]' "${CSV_FILE}"
  yq ea -i 'select(fi==0).spec.install.spec.clusterPermissions[0].rules = select(fi==1).rules + select(fi==2).rules | select(fi==0)' \
    "${CSV_FILE}" \
		"${CRD_DIR}/021-ClusterRole-strimzi-cluster-operator-role.yaml" \
    "${CRD_DIR}/030-ClusterRole-strimzi-kafka-broker.yaml"

  # Update deployment section (operator-sdk removes fields with empty string values)
  yq ea -i ".spec.install.spec.deployments = [{\"name\": \"${PACKAGE_NAME}-v${BUNDLE_VERSION}\", \"spec\": null}]" "${CSV_FILE}"
  yq ea -i "select(fi==0).spec.install.spec.deployments[0].spec = select(fi==1).spec | select(fi==0)" "${CSV_FILE}" "${CRD_DIR}/060-Deployment-strimzi-cluster-operator.yaml"
  
  # Remove resource sections as it was causing problems with OLM in the past
  yq ea -i 'del(.spec.install.spec.deployments[0].spec.template.spec.containers[0].resources)' "${CSV_FILE}"
  # Set strategy to recreate
  yq ea -i '.spec.install.spec.deployments[0].spec.strategy.type = "Recreate"' "${CSV_FILE}"
  # Set namespace properly
  yq ea -i ".spec.install.spec.deployments[0].spec.template.spec.containers[0].env[0].valueFrom.fieldRef.fieldPath = \"metadata.annotations['olm.targetNamespaces']\"" "${CSV_FILE}"

  yq ea -i ".spec.replaces = \"${PREVIOUS_BUNDLE_VERSION}\" | .spec.replaces style=\"\"" "${CSV_FILE}"

  generate_related_images
  generate_image_digests
}

validate_olm_bundle() {
  operator-sdk bundle validate "${BUNDLE}" --select-optional name=operatorhub
}

generate_related_images() {
  # Create relatedImages section
  yq ea -i '.spec.relatedImages = null' "${CSV_FILE}"

  # Add operator image
  image=$(yq ea ".. | select(has(\"image\")) | (select (.name == \"strimzi-cluster-operator\")).image" "${CSV_FILE}")
  yq ea -i ".spec.relatedImages += [{\"name\": \"strimzi-operator\", \"image\": \"$image\"}]" "${CSV_FILE}";
  yq ea -i ".metadata.annotations.containerImage = \"$image\"" "${CSV_FILE}"

  # Add Kafka images
  KAFKA_IMAGE_VALUES=$(yq eval '.. | select(has("name")).env[] | (select (.name == "STRIMZI_KAFKA_IMAGES")).value' "${CSV_FILE}")
  for val in $KAFKA_IMAGE_VALUES;
  do
    name="strimzi-kafka-$(echo "$val" | cut -d'=' -f1 | tr -d '.')";
    image=$(echo "${val}" | cut -d'=' -f2);
    yq ea -i ".spec.relatedImages += [{\"name\": \"$name\", \"image\": \"$image\"}]" "${CSV_FILE}";
  done

  # Add auxiliary images
  ENV="*BRIDGE* *JMXTRANS* *KANIKO_EXECUTOR*"
  for env in $ENV;
  do
    image=$(yq ea ".. | select(has(\"name\")).env[] | (select (.name == \"$env\")).value" "${CSV_FILE}")
    name="strimzi-$(echo "$env" | $SED 's/*//g' | $SED 's/_/-/g' | tr '[:upper:]' '[:lower:]')"
    yq ea -i ".spec.relatedImages += [{\"name\": \"$name\", \"image\": \"$image\"}]" "${CSV_FILE}";
  done
}

# Iterates through images listed in newly generated relatedImages section
# and replaces image tags with image digests
generate_image_digests() {

  IMAGES=$(yq eval '.spec.relatedImages[].image' "${CSV_FILE}")
  for image_tag in $IMAGES;
  do
    tag=$(echo "$image_tag" | cut -d':' -f2);
    image=$(echo "$image_tag" | cut -d':' -f1);
    repo=$(echo "$image" | rev | cut -d'/' -f1 | rev);
    
    if [ "$repo" != "kafka-bridge" ]; then
      tag=$(echo "$tag" | $SED "s/$(echo "$tag" | cut -d'-' -f1)/${DOCKER_TAG}/g")
    fi
    registry=$DOCKER_REGISTRY;
    org=$DOCKER_ORG;

    image="${registry}/${org}/${repo}"
    echo "Get digest from remote registry for image: ${image}:${tag}"
    echo "${repo}"
    if [ "${repo}" == "kafka" ]; then
    	digest=$(skopeo inspect --override-arch ${ARCH} --format "{{ .Digest }}" "docker://${image}:$tag-${ARCH}")
    else
    	digest=$(skopeo inspect --override-arch ${ARCH} --format "{{ .Digest }}" "docker://${image}:$tag-${ARCH}")
    fi
    image_digest="${image}@${digest}"

    echo "Replacing $image_tag with $image_digest"
    $SED -i.bak "s|${image_tag}|${image_digest}|g" "${CSV_FILE}";
		rm "${CSV_FILE}.bak"
  done
}

build_bundle_images() {

	cat <<-EOF > ${BUNDLE}/Dockerfile
		FROM scratch

		# We are pushing an operator-registry bundle
		# that has both metadata and manifests.
		LABEL operators.operatorframework.io.bundle.mediatype.v1=registry+v1
		LABEL operators.operatorframework.io.bundle.manifests.v1=manifests/
		LABEL operators.operatorframework.io.bundle.metadata.v1=metadata/
		LABEL operators.operatorframework.io.bundle.package.v1=strimzi-kafka-operator
		LABEL operators.operatorframework.io.bundle.channels.v1=stable
		LABEL operators.operatorframework.io.bundle.channel.default.v1=stable

		ADD /manifests /manifests
		ADD /metadata /metadata
		EOF

    ${BUILD_ENGINE} build -t ${BUNDLE_IMAGE}:${BUNDLE_IMAGE_TAG} ${BUNDLE} --override-arch ${ARCH}
    ${BUILD_ENGINE} push "${BUNDLE_IMAGE}:${BUNDLE_IMAGE_TAG}"
    BUNDLE_DIGEST=$(skopeo inspect --override-arch ${ARCH} --format "{{ .Digest }}" "docker://${BUNDLE_IMAGE}:${BUNDLE_IMAGE_TAG}")

	echo '*****'
	echo
	echo "Pushed strimzi-kafka-operator OLM bundle image to ${BUNDLE_IMAGE}:${BUNDLE_IMAGE_TAG}"
	echo "Pushed strimzi-kafka-operator OLM bundle image to ${BUNDLE_IMAGE}:${BUNDLE_DIGEST}"
	echo "Done"
	echo
	echo '*****'
}

build_catalog_image() {
	rm -rf ${CATALOG_DIR}
	mkdir -p ${CATALOG_DIR}/strimzi
	cd ${CATALOG_DIR}
	opm generate dockerfile strimzi
	cp ../csv-template/bases/operator.yaml strimzi/operator.yaml

	PREVIOUS_BUNDLE_VERSION_SHORT=$(echo "${PREVIOUS_BUNDLE_VERSION}" | cut -d'v' -f 2 )

	${SED} -i "s#NEW_VERSION#${BUNDLE_VERSION}#g" strimzi/operator.yaml
	${SED} -i "s#OLD_VERSION#${PREVIOUS_BUNDLE_VERSION_SHORT}#g" strimzi/operator.yaml

	STRIMZI_RELEASED_BUNDLE=quay.io/operatorhubio/strimzi-kafka-operator

	opm render "${STRIMZI_RELEASED_BUNDLE}:v${PREVIOUS_BUNDLE_VERSION_SHORT}" --output=yaml >> strimzi/operator.yaml
	opm render "${BUNDLE_IMAGE}@${BUNDLE_DIGEST}" --output=yaml >> strimzi/operator.yaml
	opm validate strimzi

	podman build . -t ${INDEX_IMAGE}:${INDEX_IMAGE_TAG} -f strimzi.Dockerfile --override-arch ${ARCH}
	podman push ${INDEX_IMAGE}:${INDEX_IMAGE_TAG}

	INDEX_IMAGE_DIGEST=$(skopeo inspect --override-arch ${ARCH} --format "{{ .Digest }}" "docker://${INDEX_IMAGE}:${INDEX_IMAGE_TAG}")

	echo '*****'
	echo
	echo "Pushed strimzi-kafka-operator OLM index image to ${INDEX_IMAGE}:${INDEX_IMAGE_TAG}"
	echo "Pushed strimzi-kafka-operator OLM index image to ${INDEX_IMAGE}@${INDEX_IMAGE_DIGEST}"
	echo "Pushed strimzi-kafka-operator OLM bundle image to ${BUNDLE_IMAGE}:${BUNDLE_IMAGE_TAG}"
	echo "Pushed strimzi-kafka-operator OLM bundle image to ${BUNDLE_IMAGE}@${BUNDLE_DIGEST}"
	echo "Done"
	echo
	echo '*****'
}

generate_olm_bundle
validate_olm_bundle
build_bundle_images
build_catalog_image
